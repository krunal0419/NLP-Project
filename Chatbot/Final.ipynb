{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7941\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7941/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stemmer import Stemmer\n",
    "from difflib import SequenceMatcher  # Add this import statement\n",
    "\n",
    "\n",
    "# Function to process input\n",
    "def predict_disease(input_text):\n",
    "    data = pd.read_excel(\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "    output = \"\"\n",
    "\n",
    "    s1 = \"રોગ\"\n",
    "    if input_text.startswith(s1):\n",
    "        flag = 1\n",
    "        stemmer = Stemmer()\n",
    "        stemmed_text = stemmer.stem(input_text)\n",
    "        stemmed_words = re.split(r'[;|,|\\s]\\s*', stemmed_text)\n",
    "\n",
    "        diseases_dire = []\n",
    "\n",
    "        for i in range(len(stemmed_words)):\n",
    "            for col in data['રોગ']:\n",
    "                if stemmed_words[i] == col and stemmed_words[i] != 'રોગ':\n",
    "                    diseases_dire.append(stemmed_words[i])\n",
    "\n",
    "        if len(diseases_dire) > 0:\n",
    "            output = \"રોગો મેળ ખાતા ફોર્મ ડેટાસેટ: \" + \", \".join(diseases_dire)\n",
    "        else:\n",
    "            output = \"કોઈ રોગ મેળ ખાતો નથી.\"\n",
    "    else:\n",
    "        flag = 0\n",
    "        stemmer = Stemmer()\n",
    "        input_text = input_text.replace(\"અને\", \",\")\n",
    "        stemmed_text = stemmer.stem(input_text)\n",
    "        stemmed_words = re.split(r'(;|,|\\s)\\s*', stemmed_text)\n",
    "\n",
    "        f = open(\"guj_pos_tag.txt\", mode='r', encoding='UTF-8')\n",
    "        data = f.read()\n",
    "        sentences = data.split('\\n')[1:]\n",
    "        words = []\n",
    "        for s in sentences:\n",
    "            words.append(s.split('\\t')[1])\n",
    "\n",
    "        for i in range(len(sentences)):\n",
    "            words[i] = re.sub(r'[^.A-Zઁ-૱\\\\,_-]', ' ', words[i])\n",
    "        pairs = []\n",
    "        for i in range(len(words)):\n",
    "            pairs.append(words[i].split(\" \"))\n",
    "        tagged_guj_sentences = []\n",
    "\n",
    "        for i in range(len(pairs)):\n",
    "            for j in range(len(pairs[i])):\n",
    "                if len(pairs[i][j].split(\"\\\\\")) == 2:\n",
    "                    k, v = pairs[i][j].split(\"\\\\\")\n",
    "                    tagged_guj_sentences.append((k, v))\n",
    "\n",
    "        vocab = [word for word, tag in tagged_guj_sentences]\n",
    "        tags = [tag for word, tag in tagged_guj_sentences]\n",
    "\n",
    "        stemmer = Stemmer()\n",
    "        stem_words = []\n",
    "        for v in vocab:\n",
    "            stem_words.append(stemmer.stem(v))\n",
    "        noun_words_intxt = dict(zip(stem_words, tags))\n",
    "\n",
    "        compared_words = []\n",
    "        maxn = 0\n",
    "        for j in range(len(stemmed_words)):\n",
    "            for key, value in noun_words_intxt.items():\n",
    "                if value != 'મ':\n",
    "                    if value == 'N_NN' or value == 'RD_PUNC':\n",
    "                        if stemmed_words[j] == key:\n",
    "                            compared_words.append(stemmed_words[j])\n",
    "\n",
    "        def listToString(s):\n",
    "            str1 = \"\"\n",
    "            for ele in s:\n",
    "                str1 = str1 + ele + \" \"\n",
    "            return str1\n",
    "\n",
    "        listnoun = listToString(compared_words)\n",
    "        symptoms_byuser = re.split(r'[,]\\s*', listnoun)\n",
    "        symptoms_byuser = np.array(symptoms_byuser)\n",
    "        for i in range(len(symptoms_byuser)):\n",
    "            symptoms_byuser[i] = symptoms_byuser[i].strip()\n",
    "\n",
    "        symptoms_byuser = symptoms_byuser.tolist()\n",
    "\n",
    "        symptoms_byuser = np.array(symptoms_byuser)\n",
    "        data = pd.read_excel(\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "        symptoms = []\n",
    "        max_n = []\n",
    "        symptom = 0\n",
    "\n",
    "        for i in range(len(symptoms_byuser)):\n",
    "            maxn = 0\n",
    "            for col in data.columns:\n",
    "                ratio = SequenceMatcher(None, col, symptoms_byuser[i]).ratio()\n",
    "                if ratio != 0 and maxn < ratio:\n",
    "                    maxn = ratio\n",
    "                    symptom = col\n",
    "            max_n.append(maxn * 100)\n",
    "            symptoms.append(symptom)\n",
    "\n",
    "    output = \"\\n\".join([f\"{symptom}\\n{maxn:.2f} %\" for symptom, maxn in zip(symptoms, max_n)])\n",
    "\n",
    "    return output\n",
    "\n",
    "iface1 = gr.Interface(\n",
    "    fn=predict_disease,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    live=True,\n",
    "    title=\"Gujarati Disease Predictor\",\n",
    "    description=\"Enter a disease or symptoms in Gujarati to get related information.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface1.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7942\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7942/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stemmer import Stemmer\n",
    "from difflib import SequenceMatcher  # Add this import statement\n",
    "\n",
    "# Function to process input\n",
    "data = pd.read_excel (\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "\n",
    "input_text =  input(\"Enter the disease:\") \n",
    "\n",
    "s1=\"રોગ\"\n",
    "if input_text.startswith(s1): \n",
    "    flag=1\n",
    "    stemmer = Stemmer()\n",
    "    stemmed_text = stemmer.stem(input_text)\n",
    "    stemmed_words = re.split(r'[;|,|\\s]\\s*', stemmed_text) \n",
    "\n",
    "    diseases_dire=[]\n",
    "\n",
    "    for i in range(len(stemmed_words)): \n",
    "        for col in data['રોગ']: \n",
    "            if(stemmed_words[i]==col and stemmed_words[i]!='રોગ'):\n",
    "                diseases_dire.append(stemmed_words[i])\n",
    "\n",
    "    print(\"રોગો મેળ ખાતા ફોર્મ ડેટાસેટ : \",diseases_dire)\n",
    "    diseases_dire=np.array(diseases_dire)\n",
    "\n",
    "    data2 = pd.read_excel (\"Gujarati_Dataset2.xlsx\")\n",
    "\n",
    "    Y = data2[data2.columns[0]].as_matrix()\n",
    "    disease = Y.tolist()\n",
    "\n",
    "    lendisease2=len(disease)\n",
    "\n",
    "    columnnum=[]\n",
    "    diseases_dire=np.array(diseases_dire)\n",
    "    for i in range(lendisease2):\n",
    "        for j in diseases_dire:\n",
    "            if j ==  disease[i]:\n",
    "                columnnum.append(i)\n",
    "\n",
    "    disease_row=data2.loc[columnnum,:]\n",
    "    disease_row=disease_row.to_numpy()\n",
    "    \n",
    "\n",
    "else:       \n",
    "    flag=0\n",
    "    stemmer = Stemmer()\n",
    "    input_text=input_text.replace(\"અને\", \",\")\n",
    "    stemmed_text = stemmer.stem(input_text)\n",
    "    stemmed_words = re.split(r'(;|,|\\s)\\s*', stemmed_text) \n",
    "    print()\n",
    "   \n",
    "    f = open(\"guj_pos_tag.txt\",mode='r',encoding='UTF-8')\n",
    "    data = f.read()\n",
    "    sentences = data.split('\\n')[1:]\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        words.append(s.split('\\t')[1])\n",
    "\n",
    "    import re\n",
    "    for i in range(len(sentences)):\n",
    "        words[i] = re.sub(r'[^.A-Zઁ-૱\\\\,_-]',' ',words[i])\n",
    "    pairs = []\n",
    "    for i in range(len(words)):\n",
    "        pairs.append(words[i].split(\" \"))\n",
    "    tagged_guj_sentences = []\n",
    "\n",
    "    for i in range(len(pairs)):\n",
    "        for j in range(len(pairs[i])):\n",
    "            if len(pairs[i][j].split(\"\\\\\")) ==2:\n",
    "                k,v = pairs[i][j].split(\"\\\\\")\n",
    "                tagged_guj_sentences.append((k,v))\n",
    "\n",
    "    vocab=[word for word,tag in tagged_guj_sentences]\n",
    "    tags=[tag for word,tag in tagged_guj_sentences]\n",
    "\n",
    "    from stemmer import Stemmer\n",
    "    stemmer = Stemmer()\n",
    "    stem_words = []\n",
    "    for v in vocab:\n",
    "        stem_words.append(stemmer.stem(v))\n",
    "    noun_words_intxt = dict(zip(stem_words,tags))\n",
    "    noun_words_intxt = [(k, v) for k, v in noun_words_intxt.items()]  \n",
    "\n",
    "    from difflib import SequenceMatcher\n",
    "    compared_words=[]\n",
    "    maxn=0\n",
    "    for j in range(len(stemmed_words)):\n",
    "        for i in range(len(noun_words_intxt)):\n",
    "            if(noun_words_intxt[i][0]!='મ'):\n",
    "                if(noun_words_intxt[i][1]=='N_NN' or noun_words_intxt[i][1]=='RD_PUNC' ):\n",
    "                    #print(noun_words_intxt[i][0],stemmed_words[j])\n",
    "                    if(stemmed_words[j]==noun_words_intxt[i][0]):\n",
    "                        #print(noun_words_intxt[i][0],stemmed_words[j])\n",
    "                        compared_words.append(stemmed_words[j])\n",
    "    \n",
    "    def listToString(s):  \n",
    "\n",
    "        str1 = \"\"  \n",
    "\n",
    "        for ele in s:  \n",
    "            str1 =str1+ele+\" \"   \n",
    "\n",
    "        return str1  \n",
    "\n",
    "    listnoun=listToString(compared_words)\n",
    "    symptoms_byuser =  re.split(r'[,]\\s*', listnoun) \n",
    "    symptoms_byuser=np.array(symptoms_byuser)\n",
    "    for i in range(len(symptoms_byuser)):\n",
    "        symptoms_byuser[i]=symptoms_byuser[i].strip()\n",
    "        \n",
    "    symptoms_byuser=symptoms_byuser.tolist()\n",
    "\n",
    "    symptoms_byuser=np.array(symptoms_byuser)\n",
    "\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    data = pd.read_excel (\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "    symptoms=[]\n",
    "    max_n=[]\n",
    "    symptom=0\n",
    "    \n",
    "\n",
    "    for i in range(len(symptoms_byuser)): \n",
    "        maxn=0\n",
    "        for col in data.columns: \n",
    "            #print(symptoms_byuser[i])\n",
    "            ratio = SequenceMatcher(None, col, symptoms_byuser[i]).ratio()\n",
    "            if(ratio!=0 and maxn<ratio):\n",
    "                maxn=ratio\n",
    "                symptom=col\n",
    "        max_n.append(maxn*100)\n",
    "        symptoms.append(symptom)\n",
    "\n",
    "    data = pd.read_excel (\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "    i=0\n",
    "    a = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        a.append(col) \n",
    "        i=i+1\n",
    "\n",
    "    a.pop() \n",
    "    l=len(a)\n",
    "    s = [0] * l \n",
    "\n",
    "    import nltk\n",
    "    symptoms_word = symptoms\n",
    "    for i in symptoms_word:\n",
    "        s[a.index(i)]=1\n",
    "\n",
    "    s=np.array(s)\n",
    "    s=s.reshape(-1,1)\n",
    "    s.shape\n",
    "    s=s.T\n",
    "\n",
    "    alldiseases = []\n",
    "    for i in symptoms_word: \n",
    "        for k in range (41):\n",
    "            if data[i][k] == 1:    \n",
    "                alldiseases.append(data['રોગ'][k])  \n",
    "\n",
    "    def countfreq(alldiseases):\n",
    "        freq_diseases = dict()\n",
    "\n",
    "        for elem in alldiseases: \n",
    "            if elem in freq_diseases:\n",
    "                freq_diseases[elem] += 1\n",
    "            else:\n",
    "                freq_diseases[elem] = 1    \n",
    "\n",
    "        freq_diseases = { key:value for key, value in freq_diseases.items() if value >= len(symptoms_word)}\n",
    "        return freq_diseases\n",
    "\n",
    "    freq_diseases = countfreq(alldiseases)   \n",
    "    freq_diseases = list(freq_diseases.items())\n",
    "    commondiseases = np.array(freq_diseases)\n",
    "\n",
    "    data = pd.DataFrame(commondiseases)\n",
    "    data=data[data.columns[:-1]]\n",
    "    commondiseases=data.to_numpy()\n",
    "\n",
    "    print()\n",
    "    if len(commondiseases) != 0:\n",
    "        alldiseases=commondiseases\n",
    "        output_text = alldiseases\n",
    "    else:\n",
    "        x = np.array(alldiseases) \n",
    "        alldiseases=np.unique(x)\n",
    "        output_text = alldiseases\n",
    "\n",
    "    def display_output(તમને_થઈ_શકે_તેવા_રોગની_સંભાવનાઓ):\n",
    "        return output_text\n",
    "\n",
    "    iface = gr.Interface(fn=display_output, inputs=\"text\", outputs=\"text\")\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91996\\AppData\\Local\\Temp\\ipykernel_19944\\2259719346.py:37: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if features != []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7943\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7943/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7944\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7944/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7945\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7945/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "data = pd.read_excel (\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "disease=data.iloc[:, -1]\n",
    "len_disease=len(disease)\n",
    "\n",
    "len_alldisease=len(alldiseases)\n",
    "Number=[]\n",
    "\n",
    "j=0\n",
    "for i in range(len_disease):\n",
    "    if j != len_alldisease:\n",
    "        if alldiseases[j] ==  disease[i]:\n",
    "            Number.append(i)\n",
    "            j=j+1\n",
    "    i=i+1\n",
    "\n",
    "feature_row=data.loc[Number,:]\n",
    "feature_row=feature_row.to_numpy()\n",
    "\n",
    "features=[]\n",
    "for j in range(len_alldisease):\n",
    "    if j !=len_alldisease:\n",
    "        for i in range(128):\n",
    "            if feature_row[j][i] == 1:\n",
    "                features.append(a[i])\n",
    "            i=i+1\n",
    "\n",
    "for k in range(len(symptoms_word)):\n",
    "    j=0\n",
    "    for j in features:\n",
    "        if symptoms_word[k] == j:\n",
    "            features.remove(j);           \n",
    "    k=k+1   \n",
    "\n",
    "features=np.unique(features)\n",
    "\n",
    "if features != []:\n",
    "    output2 = features\n",
    "def display_output2(આ_અન્ય_લક્ષણો_છે):\n",
    "    return output2\n",
    "\n",
    "iface = gr.Interface(fn=display_output2, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n",
    "lst = [ ] \n",
    "n = len(features)\n",
    "s=s.T\n",
    "output3 = []\n",
    "for m in features: \n",
    "    ele = inputs = (input())\n",
    "    if ele == \"stop\":\n",
    "        break\n",
    "    if ele != \"0\":\n",
    "        s[a.index(m)]=1\n",
    "    if ele!=\"1\" and ele !=\"0\":\n",
    "        break\n",
    "    output3 = output3 + [m]    \n",
    "def display_output3(પ્રદાન_કરાયેલા_લક્ષણો_છે):\n",
    "    return output3\n",
    "\n",
    "iface = gr.Interface(fn=display_output3, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n",
    "s=s.T\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data_temp = pd.read_excel (\"Gujarati_Training.xlsx\")\n",
    "X = data_temp.iloc[:, :-1].values\n",
    "Y = data_temp.iloc[:, -1].values\n",
    "y = labelencoder.fit_transform(Y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(X, y)\n",
    "pr1= classifier.predict(s)\n",
    "R1=labelencoder.inverse_transform(pr1)\n",
    "\n",
    "data = pd.read_excel (\"Gujarati_Dimensionality_Reduction.xlsx\")\n",
    "disease_original=data.loc[data['રોગ'].isin(R1)]\n",
    "temp=disease_original.drop(columns=['રોગ'])\n",
    "disease_original = np.array(temp)\n",
    "s=np.array(s)\n",
    "\n",
    "count=0\n",
    "total=0\n",
    "\n",
    "for j in range(len(disease_original.T)):\n",
    "    if (disease_original.T[j]==1):\n",
    "        total=total+1\n",
    "\n",
    "for i in range(len(disease_original.T)):\n",
    "    if (s.T[i]==disease_original.T[i] and disease_original.T[i]==1):\n",
    "        count=count+1\n",
    "\n",
    "prp = (count / total) * 100\n",
    "output = \"\\n\".join([f\"{R1}\\n{prp:.2f} %\"])\n",
    "\n",
    "def display_output(દાખલ_કરેલા_લક્ષણો_પરથી_રોગ_થવાની_સંભાવના):\n",
    "    return output\n",
    "\n",
    "iface = gr.Interface(fn=display_output, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7946\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7946/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7947\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7947/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7948\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7948/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7949\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7949/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = pd.read_excel (\"Gujarati_Dataset2.xlsx\")\n",
    "\n",
    "Y = data2[data2.columns[0]].values\n",
    "disease = Y.tolist()\n",
    "\n",
    "lendisease2=len(disease)\n",
    "\n",
    "columnnum=[]\n",
    "j=0\n",
    "for i in range(lendisease2):\n",
    "    if R1 ==  disease[i]:\n",
    "        columnnum.append(i)\n",
    "\n",
    "disease_row=data2.loc[columnnum,:]\n",
    "disease_row=disease_row.to_numpy()\n",
    "\n",
    "Description = 1\n",
    "\n",
    "output1=(disease_row[0][1])\n",
    "def display_output(રોગનું_વર્ણન):\n",
    "    return output1\n",
    "iface = gr.Interface(fn=display_output, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n",
    "output2=(disease_row[0][2])\n",
    "def display_output2(રોગ_નિવારણ_પદ્ધતિઓ):\n",
    "    return output2\n",
    "iface = gr.Interface(fn=display_output2, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n",
    "output3=(disease_row[0][3])\n",
    "def display_output3(ઘરગથ્થુ_ઉપચાર):\n",
    "    return output3\n",
    "iface = gr.Interface(fn=display_output3, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "\n",
    "output4 = (disease_row[0][4])\n",
    "def display_output4(રોગનૂ_ઉપચાર):\n",
    "    return output4\n",
    "iface = gr.Interface(fn=display_output4, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
